experiment: 'chestxray'

seed: &seed 0

imagenet_mean: &image_mean
- 0.449
imagenet_std: &image_std
- 0.226

image_w: &image_w 320
image_h: &image_h 320
image_c: &image_c 3  # the desired number of channels

n_epochs: &n_epochs 50
batch_size: &batch_size 32

n_classes: &n_classes 4  # background class included

data:
  source_path: &source_path /mimer/NOBACKUP/groups/lupida/data/chestxray/ChestXray-NIHCC
  target_path: &target_path /mimer/NOBACKUP/groups/lupida/data/chestxray/CheXpert-v1.0-small
  seed: *seed  # used for ADAPT models
  pipeline:
    type: dalupi.data.chestxray.Pipeline3
    is_called: true
    source_path: *source_path
    target_path: *target_path
    num_train_source: 60000
    num_train_target: 60000
    num_valid_source: 10000
    num_valid_target: 10000
    num_test_source: 10000
    num_test_target: 10000
    num_train_sample: 457
    seed: *seed

finetuning:
  lr: 1.0e-5  # all learning rates will be set to this value
  max_epochs: 20
  n_layers: 5

results:
  path: /mimer/NOBACKUP/groups/lupida/models/chestxray

default:
  module:
    type: dalupi.models.networks.BaseNetwork
    is_called: false
    featurizer:
      type: dalupi.models.networks.ResNet
      is_called: false
    featurizer__version: 50
    featurizer__grayscale_input: true
    featurizer__pretrained: true
    featurizer__n_trainable_layers: 0
    featurizer__p_dropout: 0
    task:
      type: dalupi.models.networks.Task
      is_called: false
    task__out_features: *n_classes
    task__is_nonlinear: true
  criterion:
    type: torch.nn.BCEWithLogitsLoss
    is_called: false
    reduction: none
  optimizer:
    type: torch.optim.Adam
    is_called: false
  optimizer__weight_decay: 0
  lr: 1.0e-4
  max_epochs: *n_epochs
  batch_size: *batch_size
  iterator_train:
    shuffle: true
  dataset:
    type: dalupi.data.chestxray.BaseDataset
    is_called: false
    transforms: &transforms
    - type: torchvision.transforms.ToTensor
      is_called: true
    - type: torchvision.transforms.Resize
      is_called: true
      size:
      - *image_w
      - *image_h
    - type: torchvision.transforms.Normalize
      is_called: true
      mean: *image_mean
      std: *image_std
  train_split:
    type: dalupi.data.utils.TrainValidSplit
    is_called: true
  callbacks:
  - - 'lr_scheduler'
    - type: skorch.callbacks.LRScheduler
      is_called: True
      policy: StepLR
      step_size: 1.0e+3
      gamma: 0.1
  predict_nonlinearity:
    type: torch.sigmoid
    is_called: false
  verbose: 1
  device:
    type: dalupi.utils.get_device
    is_called: true

source: &source
  finetune: true
  model:
    type: dalupi.models.models.BaseModel
    is_called: false
    multilabel: true
    epoch_scoring: 'auc'
    monitor: 'valid_auc_best'
    load_best: true
    patience: 10
    seed: *seed

target: *source

dalupi:
  finetune: true
  model:
    type: dalupi.models.models.DALUPI
    is_called: false
    multilabel: true
    epoch_scoring: 'auc'
    monitor: 'valid_auc_best'
    load_best: true
    patience: 10
    seed: *seed
  module:
    type: dalupi.models.networks.DALUPI
    is_called: false
    out_features: *n_classes
    backbone_weights: IMAGENET1K_V2
    backbone_n_trainable_layers: 0
    backbone_grayscale_input: true
    rpn_anchor_sizes:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
    rpn_aspect_ratios:
    - - 0.5
      - 1.0
      - 2.0
    rpn_fg_iou_thresh: 0.7
    rpn_bg_iou_thresh: 0.3
    rpn_batch_size_per_image: 128
    rpn_positive_fraction: 0.5
    rpn_pre_nms_top_n:
      training: 2000
      testing: 1000
    rpn_post_nms_top_n:
      training: 2000
      testing: 1000
    rpn_nms_thresh: 0.7
    rpn_score_thresh: 0.0
    box_roi_pool_output_size: 7
    box_roi_pool_sampling_ratio: 2
    box_head_output_size: 1024
    box_fg_iou_thresh: 0.5
    box_bg_iou_thresh: 0.5
    box_batch_size_per_image: 512
    box_positive_fraction: 0.25
    box_bbox_reg_weights: null
    box_score_thresh: 0.05
    box_nms_thresh: 0.5
    box_detections_per_img: 100
    transform_min_size: 320
    transform_max_size: 320
    transform_image_mean: *image_mean
    transform_image_std: *image_std
  iterator_train:
    collate_fn:
      type: dalupi.data.utils.collate_fn
      is_called: false
  iterator_valid:
    collate_fn:
      type: dalupi.data.utils.collate_fn
      is_called: false
  dataset:
    type: dalupi.data.chestxray.DALUPIDataset
    is_called: false
    transforms:
      train:
      - type: dalupi.models.transforms.ToTensor
        is_called: true
      eval:
      - type: dalupi.models.transforms.ToTensor
        is_called: true
  predict_nonlinearity: null

dann:
  finetune: false
  model:
    type: dalupi.models.models.DANN
    is_called: false
    multilabel: true
    epoch_scoring: 'auc'
    monitor: 'valid_auc_best'
    f_optimizer: null
    load_best: true
    patience: 10
    d_steps_per_g_step: 1
    grad_penalty: 0
    theta: 0.1
    optimizer_generator:
      type: torch.optim.Adam
      is_called: false
    optimizer_generator__weight_decay: 0
    optimizer_discriminator:
      type: torch.optim.Adam
      is_called: false
    optimizer_discriminator__weight_decay: 0
    seed: *seed
  module:
    type: dalupi.models.networks.DANN
    is_called: false
    featurizer: 
      type: dalupi.models.networks.ResNet
      is_called: false
    featurizer__version: 50
    featurizer__grayscale_input: true
    featurizer__pretrained: true
    featurizer__n_trainable_layers: 3
    featurizer__p_dropout: 0
    classifier:
      type: dalupi.models.networks.Task
      is_called: false
    classifier__out_features: *n_classes
    classifier__is_nonlinear: true
    discriminator:
      type: dalupi.models.networks.MLP
      is_called: false
    discriminator__out_features: 2  # number of domains
    discriminator__width: 256
    discriminator__depth: 3
    discriminator__p_dropout: 0
  dataset:
    type: dalupi.data.chestxray.DANNDataset
    is_called: false
    transforms: *transforms
  callbacks:
  - - 'lr_scheduler'
    - type: dalupi.models.utils.MultiOptimLRScheduler
      is_called: true
      policies: StepLR
      step_size: 1.0e+3
      gamma: 0.1

adapt_dann:
  finetune: false
  model:
    type: adapt.feature_based.DANN
    is_called: true
    encoder: &adapt_encoder
      type: dalupi.models.networks.get_adapt_encoder
      is_called: true
      weights: imagenet
      n_trainable_layers: 3
      dropout: 0
      input_shape:
      - *image_w
      - *image_h
      - *image_c
    task: &adapt_task
      type: dalupi.models.networks.get_adapt_task
      is_called: true
      in_features: 2048  # the output of the encoder (ResNet-50)
      out_features: *n_classes
      is_nonlinear: true
      dropout: 0
    discriminator: &adapt_discriminator
      type: dalupi.models.networks.get_adapt_discriminator
      is_called: true
      depth: 3
      width: 256
      n_domains: 2
      dropout: 0
    lambda_:
      type: tensorflow.Variable
      is_called: true
      initial_value: 0.0
    verbose: 1
    random_state: *seed
    optimizer: &adapt_optimizer
      type: tensorflow.keras.optimizers.Adam
      is_called: true
      learning_rate:
        type: dalupi.models.utils.MyDecay
        is_called: true
        mu_0: 1.0e-4
        alpha: 0
        max_steps: 10000
      weight_decay: null
    loss: &adapt_loss
      type: tensorflow.keras.losses.BinaryCrossentropy
      is_called: true
      from_logits: true
    metrics: &adapt_metrics
      disc:
      - accuracy
      task:
      - type: tensorflow.keras.metrics.AUC
        is_called: true
        name: task_auc
        multi_label: true
        from_logits: true
    optimizer_enc: &adapt_optimizer_enc
      type: tensorflow.keras.optimizers.Adam
      is_called: true
      learning_rate:
        type: dalupi.models.utils.MyDecay
        is_called: true
        mu_0: 1.0e-4
        alpha: 0
        max_steps: 10000
      weight_decay: null
    optimizer_disc: &adapt_optimizer_disc
      type: tensorflow.keras.optimizers.Adam
      is_called: true
      learning_rate:
        type: dalupi.models.utils.MyDecay
        is_called: true
        mu_0: 1.0e-4
        alpha: 0
        max_steps: 10000
      weight_decay: null
    epochs: *n_epochs
    batch_size: *batch_size
    callbacks: &adapt_callbacks
      early_stopping:
        type: tensorflow.keras.callbacks.EarlyStopping
        is_called: true
        monitor: val_task_auc
        patience: 10
      model_checkpoint:
        type: tensorflow.keras.callbacks.ModelCheckpoint
        is_called: true
        filepath: null  # filepath is set internally
        monitor: val_task_auc
        verbose: 1
        save_best_only: true
        mode: max
        save_weights_only: false
      save_training_progress:
        type: dalupi.models.utils.SaveTrainingProgress
        is_called: true
      update_lambda:
        type: adapt.utils.UpdateLambda
        is_called: true
        lambda_init: 0.0
        lambda_max: 0.1
        gamma: 1.0
        max_steps: 10000

adapt_mdd:
  finetune: false
  model:
    type: adapt.feature_based.MDD
    is_called: true
    encoder: *adapt_encoder
    task:
      type: dalupi.models.networks.get_adapt_task_norm
      is_called: true
      in_features: 2048  # the output of the encoder (ResNet-50)
      out_features: *n_classes
      is_nonlinear: true
      dropout: 0
      max_norm: 0.5
    lambda_:
      type: tensorflow.Variable
      is_called: true
      initial_value: 0.0
    gamma: 3.0
    verbose: 1
    random_state: *seed
    optimizer: *adapt_optimizer
    loss: *adapt_loss
    metrics: *adapt_metrics
    optimizer_enc: *adapt_optimizer_enc
    optimizer_disc: *adapt_optimizer_disc
    epochs: *n_epochs
    batch_size: *batch_size
    callbacks: *adapt_callbacks
